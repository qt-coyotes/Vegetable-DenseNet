{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691bc568",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.utils.data\n",
    "import torch.utils.data.distributed\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.autograd import Variable\n",
    "from torchvision.models import densenet121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d20a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "modellr = 1e-4\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 10\n",
    "#DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "DEVICE = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32103c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    " \n",
    "])\n",
    "transform_validation = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3291e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training set and validation set see google drive\n",
    "dataset_train = datasets.ImageFolder(r\"C:\\Users\\lovel\\Downloads\\rm + nonrm\", transform)\n",
    "dataset_validation = datasets.ImageFolder(r\"C:\\Users\\lovel\\Downloads\\val_set\", transform_validation)\n",
    "# read data\n",
    "#print(dataset_train.imgs)\n",
    "print(len(dataset_train),len(dataset_validation))\n",
    "print(dataset_train.class_to_idx,dataset_validation.class_to_idx) \n",
    "# import data\n",
    "train_loader = torch.utils.data.DataLoader(dataset_train, batch_size=BATCH_SIZE, shuffle=True)\n",
    "validation_loader = torch.utils.data.DataLoader(dataset_validation, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82275dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "model_ft = densenet121(pretrained=True)\n",
    "num_ftrs = model_ft.classifier.in_features\n",
    "model_ft.classifier = nn.Linear(num_ftrs, 2)\n",
    "model_ft.to(DEVICE)\n",
    "\n",
    "optimizer = optim.Adam(model_ft.parameters(), lr=modellr)\n",
    " \n",
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"\n",
    "    modellrnew = modellr * (0.1 ** (epoch // 50))\n",
    "    print(\"lr:\", modellrnew)\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = modellrnew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4519541",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(\"model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6c0e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_prob = []\n",
    "train_label = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af648612",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training\n",
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    sum_loss = 0\n",
    "    total_num = len(train_loader.dataset)\n",
    "    print(total_num, len(train_loader))\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = Variable(data).to(device), Variable(target).to(device)\n",
    "        #print(target.numpy())\n",
    "        train_label.append(target)\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        #_, pred = torch.max(output.data, 1)\n",
    "        train_prob.append(torch.sigmoid(output.data).numpy())\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print_loss = loss.data.item()\n",
    "        sum_loss += print_loss\n",
    "        if (batch_idx + 1) % 50 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, (batch_idx + 1) * len(data), len(train_loader.dataset),\n",
    "                       100. * (batch_idx + 1) / len(train_loader), loss.item()))\n",
    "    ave_loss = sum_loss / len(train_loader)\n",
    "    print('epoch:{},loss:{}'.format(epoch, ave_loss))\n",
    " \n",
    " \n",
    "# validation\n",
    "def val(model, device, validation_loader):\n",
    "    best_metric = -1\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total_num = len(validation_loader.dataset)\n",
    "    print(total_num, len(validation_loader))\n",
    "    with torch.no_grad():\n",
    "        for data, target in validation_loader:\n",
    "            data, target = Variable(data).to(device), Variable(target).to(device)\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            _, pred = torch.max(output.data, 1)\n",
    "            correct += torch.sum(pred == target)\n",
    "            print_loss = loss.data.item()\n",
    "            test_loss += print_loss\n",
    "        correct = correct.data.item()\n",
    "        acc = correct / total_num\n",
    "        avgloss = test_loss / len(validation_loader)\n",
    "        print('\\nVal set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "            avgloss, correct, len(validation_loader.dataset), 100 * acc))\n",
    "        if acc > best_metric:\n",
    "            best_metric = acc\n",
    "            torch.save(model_ft, 'model.pth')\n",
    "\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    adjust_learning_rate(optimizer, epoch)\n",
    "    train(model_ft, DEVICE, train_loader, optimizer, epoch)\n",
    "    val(model_ft, DEVICE, validation_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2296305",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting training probability for Youden index\n",
    "import numpy as np\n",
    "prob = []\n",
    "np.set_printoptions(suppress=True)\n",
    "np.set_printoptions(precision=6)\n",
    "print(train_prob)\n",
    "for i in range(len(train_prob)):\n",
    "    for j in range(len(train_prob[i])):\n",
    "        prob.append(train_prob[i][j][1])\n",
    "print(prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88f17c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting training labels for Youden index\n",
    "len(train_label)\n",
    "label = []\n",
    "for i in range(len(train_label)):\n",
    "    for j in range(len(train_label[i])):\n",
    "        label.append(train_label[i][j])\n",
    "#print(label)\n",
    "#print(len(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71ca294",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stupid way for getting testing groundtruth\n",
    "import glob\n",
    "import os\n",
    "path1 = r'C:\\Users\\lovel\\Downloads\\mange\\*'\n",
    "files1 = glob.glob(path1)\n",
    "mange = []\n",
    "path2 = r'C:\\Users\\lovel\\Downloads\\non mange\\*'\n",
    "files2 = glob.glob(path2)\n",
    "nonmange = []\n",
    "for i in range(len(files1)):\n",
    "    filename = os.path.basename(files1[i])\n",
    "    print(filename)\n",
    "    mange.append(filename)\n",
    "    #print(mange)\n",
    "\n",
    "for j in range(len(files2)):\n",
    "    filename = os.path.basename(files2[j])\n",
    "    print(filename)\n",
    "    nonmange.append(filename)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54036a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "groundtruth = []\n",
    "path3 = r'C:\\Users\\lovel\\Downloads\\test\\*'\n",
    "files3 = glob.glob(path3)\n",
    "#print(files3)\n",
    "\n",
    "for k in range(len(files3)):\n",
    "    filename = os.path.basename(files3[k])\n",
    "    #print(filename)\n",
    "    \n",
    "    #mange.append(filename)\n",
    "    if filename in mange:\n",
    "        groundtruth.append(1)\n",
    "    elif filename in nonmange:\n",
    "        groundtruth.append(0)\n",
    "\n",
    "print(groundtruth)\n",
    "y_true = numpy.array(groundtruth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78276681",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data.distributed\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "from torch.autograd import Variable\n",
    "import os\n",
    "import numpy as np\n",
    "# testing\n",
    "classes=('Nonmange','Mange')\n",
    "transform_test = transforms.Compose([\n",
    "         transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "])\n",
    "prob = []\n",
    "predict = [] \n",
    "output = []\n",
    "#DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "DEVICE = 'cpu'\n",
    "model = torch.load(\"model.pth\")\n",
    "model.eval()\n",
    "model.to(DEVICE)\n",
    "\n",
    "path=r'C:/Users/lovel/Downloads/test/'\n",
    "testList=os.listdir(path)\n",
    "i = 0\n",
    "for file in testList:\n",
    "        print(file)\n",
    "        img=Image.open(path+file)\n",
    "        img=transform_test(img)\n",
    "        img.unsqueeze_(0)\n",
    "        img = Variable(img).to(DEVICE)\n",
    "        out=model(img)\n",
    "        # Predict\n",
    "        x, pred = torch.max(torch.sigmoid(out.data), 1)\n",
    "        output.append(torch.sigmoid(out.data).numpy())\n",
    "        #print(x)\n",
    "        groundtruth.append(classes[pred.data.item()])\n",
    "        print('Image Name:{},predict:{}'.format(file,classes[pred.data.item()]))\n",
    "        \n",
    "        if pred.numpy() != 1:\n",
    "            x = 1-x.numpy()\n",
    "        print(x)\n",
    "        prob.append(x)\n",
    "        pred = pred.numpy()\n",
    "        predict.append(pred)\n",
    "        i += 1\n",
    "print(prob)\n",
    "\n",
    "y_score = torch.tensor((prob))\n",
    "print(y_score)\n",
    "#row_sums = torch.sum(y_score, 1)\n",
    "#print(row_sums)\n",
    "#row_sums = row_sums.repeat(1, 2)\n",
    "#y_score = torch.div( y_score , row_sums )\n",
    "\n",
    "y_pred = np.array(predict)\n",
    "print(y_pred)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db28506c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting testing prob for Youden index\n",
    "mange = []\n",
    "#nonmange = []\n",
    "#print(output)\n",
    "for i in range(len(output)):\n",
    "    #print(output[i][0][0])\n",
    "    #nonmange.append(output[i][0][0])\n",
    "    mange.append(output[i][0][1])\n",
    "print(mange)\n",
    "print(len(mange))\n",
    "#print(nonmange)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec66b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "\n",
    "RocCurveDisplay.from_predictions(\n",
    "    y_true, y_score.flatten(),\n",
    "#     name=f\"{class_of_interest} vs the rest\",\n",
    "    color=\"darkorange\",\n",
    ")\n",
    "plt.plot([0, 1], [0, 1], \"k--\", label=\"chance level (AUC = 0.5)\")\n",
    "plt.axis(\"square\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"One-vs-Rest ROC curves:\\nVirginica vs (Setosa & Versicolor)\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461f5926",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "tn, fp, fn, tp = confusion_matrix(y_true, y_pred.flatten()).ravel()\n",
    "(tn, fp, fn, tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ae0dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "tn = 209\n",
    "fp = 4\n",
    "fn = 1\n",
    "tp = 4\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import fbeta_score\n",
    "print(\"Precision:\", precision_score(y_true, y_pred.flatten()))\n",
    "#precision = tp / (tp + fp)\n",
    "print(\"Recall:\", recall_score(y_true, y_pred.flatten()))\n",
    "#recall = tp / (tp + fn)\n",
    "print(\"F1 score:\", f1_score(y_true, y_pred))\n",
    "#print(\"F1 score:\", 2 * (precision * recall) / (precision + recall))\n",
    "print(\"F2 score:\", fbeta_score(y_true, y_pred, beta=2))\n",
    "print(\"accuracy:\", (tp+tn)/(tp+tn+fp+fn))\n",
    "#print(\"Binary expected cost:\",(0. * tp + 1. * fp + 5. * fn + 0. * tn) / (tp + tn + fp + fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3025c598",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
